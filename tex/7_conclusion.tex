
\providecommand{\main}{..}
\documentclass[\main/thesis.tex]{subfiles}
\externaldocument{}



\begin{document}

\chapter{Conclusion, Validity, and Future Work} 

\section{Conclusion}  The goal of this project was to create an automatic system in which a virtual ear discovers new drum sounds from randomly programmed virtual synthesizers. We built and tested two generative systems for the creation of percussive sounds via automatic programming of virtual synthesizers. We verified its results with human listeners, and found that up to 70\% of the sound generated were deemed percussive by both subjects. While many avenues of improvement are available, the implementation outlined here satisfies our stated goal. 
Our work enables not only the creation of new libraries of percussion sounds, but new synthesizer programs which can be modified and studied. 
Manual listening tests revealed much room for improvement, particularly with accurate separation of percussive sounds from the infinitely large set of non-percussive sounds. We demonstrated some success in our utilization of latent representations of autoencoder networks as low-dimensional representations of short sound files, yet these results did not yield any noticeable advantage over direct usage of non-encoded features.
% Manual listening tests revealed much room for improvement, particularly with accurate separation of percussive sounds from the infinitely large set of non-percussive sounds. We had some success in our utilization of latent representations of autoencoder networks as low-dimensional representations of short sound files. \\ 
\section{Threats to Validity}
 
\subsection{Construct Validity}
  We did not measure, nor can we guarantee, the novelty of the generated drum sounds. Let's consider a system which outputs the exact same percussive sound in every iteration. This system would have achieved a perfect kappa coefficient score with 0 percent non-percussive outputs, despite having no utility in music production. 
  
\subsection{Internal Validity}
 The lack of consistency in training and accuracy measurements makes comparisons between TPEs and MEMs difficult. The models have been trained on different subsets of the 3 different drum datasets, and cross validation was utilized in measuring the MEMs but not the TPEs. The design of the virtual synthesizer---its parameters and parameter values---is loosely based on commonly found parameters in VST synthesizers, therefore, we cannot guarantee that these results will translate to other virtual synthesizers. We also did not measure what percentage of the randomly generated sounds are percussive before being filtered by the virtual ear. 
\subsection{External Validity}
 In addition, since both survey subjects have a preference for \enquote{experimental} electronic music, which may influence their perception of what is and is not an acceptable drum sound. Furthermore, both survey subjects played a role in the implementation of the project, which may influence their leniency in output sounds as percussive or non-percussive. 

  
\section{Future Work} Effective implementation of few-shot learning is a priority, as it will allow for a larger variety of sounds to be generated using our methods and possibly address the OSR problem. Program generation can be improved by reinforcement learning and other heuristics, however, we need to ensure that there is a stronger agreement between the synthetic ear's scores and human listeners. We also more specialized autoencoder architectures and training methods can improve feature extraction.

\end{document}