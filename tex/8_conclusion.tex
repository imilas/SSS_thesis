
\providecommand{\main}{..}
\documentclass[\main/thesis.tex]{subfiles}
\externaldocument{}



\begin{document}

\chapter{Conclusions, Validity, and Future Work} 

\section{Conclusions}  As proposed in our thesis statement in Section~\ref{sec:thesis_statement}, the goal of this project was to create an automatic system in which a virtual ear discovers new drum sounds from randomly programmed virtual synthesizers. We built and tested two generative systems for the creation of multiple types of drum sounds using automatic programming of virtual synthesizers. We verified its results with human listeners, and found that of the sounds generated were deemed percussive by both subjects in 70\% of the cases with the TPE system, and 50\% with the MEM. While many avenues of improvement are available, the implementation outlined here satisfies our stated goals. 
Our work enables not only the creation of new libraries of percussion sounds, but new synthesizer programs which can be modified and studied. 
Manual listening tests revealed much room for improvement, particularly with accurate separation of percussive sounds from the infinitely large set of non-percussive sounds. We demonstrated some success in our utilization of latent representations of autoencoder networks as exponentially smaller representations of audio spectrograms, yet these results did not yield any noticeable advantage over direct usage of non-encoded features.
% Manual listening tests revealed much room for improvement, particularly with accurate separation of percussive sounds from the infinitely large set of non-percussive sounds. We had some success in our utilization of latent representations of autoencoder networks as low-dimensional representations of short sound files. \\ 
\section{Threats to Validity}
 
\subsection{Construct Validity}
  We did not measure, nor can we guarantee, the novelty of the generated drum sounds. Let's consider a system which outputs the exact same percussive sound in every iteration. This system would have achieved a perfect kappa coefficient score with 0 percent non-percussive outputs, despite having no utility in music production. 
  
\subsection{Internal Validity}
 The lack of consistency in training and accuracy measurements makes comparisons between TPEs and MEMs difficult, therefore we cannot confidently say which model performed better overall. The models have been trained on different subsets of the 3 different drum datasets, and cross validation was utilized in measuring the MEMs but not the TPEs. The design of the virtual synthesizer---its parameters and parameter values---is loosely based on commonly found parameters in VST synthesizers, therefore, we cannot guarantee that these results will translate to other virtual synthesizers. We also did not measure what percentage of the randomly generated sounds are percussive before being filtered by the virtual ear. 
\subsection{External Validity}
 In addition, since both survey subjects have a preference for \enquote{experimental} electronic music, which may influence their perception of what is and is not an acceptable drum sound. Furthermore, both survey subjects played a role in the implementation of the project, which may influence their leniency in output sounds as percussive or non-percussive. 

  
\section{Future Work} Effective implementation of models that can learn with a small number of examples is a priority as it will allow for a larger variety of sounds to be generated, and perhaps address the OSR problem. Program generation can be improved by reinforcement learning or other heuristics, however, we need to ensure that there is a stronger agreement between the synthetic ear's scores and human listeners. We will also explore more specialized autoencoder architectures and training methods in order to improve feature extraction.

\end{document}